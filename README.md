# SystÃ¨me d'Alerte Clinique Multi-ParamÃ¨tres

## ğŸ“‹ Description du Projet

Ce projet implÃ©mente un systÃ¨me de dÃ©tection d'alertes cliniques basÃ© sur un modÃ¨le supervisÃ© (HistGradientBoostingClassifier). Le systÃ¨me analyse des donnÃ©es multi-paramÃ¨tres (frÃ©quence cardiaque, sommeil, activitÃ©, etc.) pour dÃ©tecter des anomalies cliniques avec une prÃ©cision de **95.21%**.

## ğŸ¯ Objectifs

- DÃ©tecter les anomalies cliniques Ã  partir de donnÃ©es multi-paramÃ¨tres
- Utiliser un feature engineering centrÃ© patient pour capturer les dÃ©viations intra-patient
- Maximiser l'accuracy tout en maintenant un recall acceptable (â‰¥ 25%)
- Fournir un pipeline reproductible pour l'entraÃ®nement et l'infÃ©rence

## ğŸ“Š DonnÃ©es

Le dataset contient les colonnes suivantes :

### Identifiants
- `patient_id` : Identifiant unique du patient
- `timestamp` ou `date` : Date/heure de l'enregistrement

### Variables Continues
- `heart_rate` : FrÃ©quence cardiaque (bpm)
- `hr_variability` : VariabilitÃ© de la frÃ©quence cardiaque
- `steps` : Nombre de pas
- `mood_score` : Score d'humeur
- `sleep_duration_hours` : DurÃ©e du sommeil (heures)
- `sleep_efficiency` : EfficacitÃ© du sommeil
- `num_awakenings` : Nombre de rÃ©veils
- `age` : Ã‚ge du patient

### Variables CatÃ©gorielles
- `weekend` : Indicateur week-end (0/1)
- `medication_taken` : Prise de mÃ©dicament (0/1)
- `is_female` : Genre fÃ©minin (0/1)
- `day_of_week` : Jour de la semaine (0-6)

### Label
- `alert_flag` : Indicateur d'alerte (0 = Normal, 1 = Anomalie)

## ğŸ”§ Ã‰tapes de Preprocessing

### 1. Tri et PrÃ©paration des DonnÃ©es

**Objectif** : Organiser les donnÃ©es par patient et par ordre chronologique.

```python
# Trier par patient_id et timestamp
df = df.sort_values(by=["patient_id", timestamp_col]).reset_index(drop=True)
```

**Pourquoi** : Les features basÃ©es sur les fenÃªtres glissantes nÃ©cessitent un ordre temporel correct.

### 2. Calcul des Statistiques Glissantes (Rolling Windows)

**Objectif** : Calculer la moyenne et l'Ã©cart-type sur une fenÃªtre de 7 jours pour chaque patient.

**Variables traitÃ©es** :
- `heart_rate`, `hr_variability`, `steps`, `mood_score`
- `sleep_duration_hours`, `sleep_efficiency`, `num_awakenings`

**MÃ©thode** :
- FenÃªtre glissante de 7 jours
- Minimum 3 observations requises
- Calcul sÃ©parÃ© pour chaque patient (groupby)

**Formule** :
```
roll_mean_t = moyenne(x_{t-6}, ..., x_t)
roll_std_t = Ã©cart-type(x_{t-6}, ..., x_t)
```

### 3. Features Delta

**Objectif** : Capturer l'Ã©cart absolu par rapport Ã  la moyenne rÃ©cente du patient.

**Formule** :
```
delta_t = x_t - roll_mean_t
```

**Exemple** : Si la frÃ©quence cardiaque moyenne d'un patient sur 7 jours est 70 bpm et qu'aujourd'hui elle est de 85 bpm, alors `heart_rate_delta = 15`.

**Pourquoi** : Ã‰limine l'effet du profil patient (certains patients ont naturellement une frÃ©quence cardiaque plus Ã©levÃ©e).

### 4. Features Z-Score

**Objectif** : Normaliser l'Ã©cart par rapport Ã  la variabilitÃ© normale du patient.

**Formule** :
```
z_score_t = delta_t / (roll_std_t + Îµ)
```
oÃ¹ Îµ = 10â»â¶ pour Ã©viter la division par zÃ©ro.

**Exemple** : Si un patient a une variabilitÃ© normale de 5 bpm et un Ã©cart de 15 bpm, alors `heart_rate_z = 3` (3 Ã©carts-types).

**Pourquoi** : Un Ã©cart de 15 bpm est plus significatif pour un patient avec une faible variabilitÃ© que pour un patient avec une forte variabilitÃ©.

### 5. Features DÃ©rivÃ©es

#### 5.1 Transformation Logarithmique des Pas
```
steps_log1p = log(1 + steps)
```
**Pourquoi** : RÃ©duit l'impact des valeurs extrÃªmes et normalise la distribution.

#### 5.2 Ratio d'Ã‰veils par Heure
```
awakenings_per_hour = num_awakenings / max(sleep_duration_hours, 0.5)
```
**Pourquoi** : Normalise le nombre de rÃ©veils par rapport Ã  la durÃ©e du sommeil.

#### 5.3 Encodage Cyclique du Jour de la Semaine
```
dow_sin = sin(2Ï€ Ã— day_of_week / 7)
dow_cos = cos(2Ï€ Ã— day_of_week / 7)
```
**Pourquoi** : Capture la cyclicitÃ© hebdomadaire (lundi et dimanche sont proches dans l'espace cyclique).

#### 5.4 Ratio FrÃ©quence Cardiaque / VariabilitÃ©
```
hr_hrv_ratio = heart_rate / max(hr_variability, 10â»Â³)
```
**Pourquoi** : Ratio physiologique important pour la santÃ© cardiovasculaire.

#### 5.5 Dette de Sommeil
```
sleep_debt = max(0, 7.5 - sleep_duration_hours)
```
**Pourquoi** : Quantifie le dÃ©ficit de sommeil par rapport Ã  une rÃ©fÃ©rence de 7.5 heures.

### 6. SÃ©lection des Features Finales

#### Features NumÃ©riques (utilisÃ©es par le modÃ¨le)
- **Delta features** : `heart_rate_delta`, `hr_variability_delta`, `steps_delta`, `mood_score_delta`, `sleep_duration_hours_delta`, `sleep_efficiency_delta`, `num_awakenings_delta`
- **Z-score features** : `heart_rate_z`, `hr_variability_z`, `steps_z`, `mood_score_z`, `sleep_duration_hours_z`, `sleep_efficiency_z`, `num_awakenings_z`
- **DÃ©rivÃ©es** : `steps_log1p`, `awakenings_per_hour`, `hr_hrv_ratio`, `sleep_debt`
- **Autres** : `age`, `dow_sin`, `dow_cos`

#### Features CatÃ©gorielles
- `weekend` (0/1)
- `medication_taken` (0/1)
- `is_female` (0/1)

### 7. Pipeline de Preprocessing

**Objectif** : Normaliser les features numÃ©riques et encoder les features catÃ©gorielles.

**MÃ©thode** :
- **Features numÃ©riques** : Normalisation avec `StandardScaler` (moyenne = 0, Ã©cart-type = 1)
- **Features catÃ©gorielles** : Encodage one-hot avec gestion des valeurs inconnues

**Code** :
```python
preprocessor = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat_cols),
    ],
    remainder="drop",
)
```

### 8. Gestion des Valeurs Manquantes

**StratÃ©gie** : Suppression des lignes avec valeurs manquantes dans les features.

**Pourquoi** : Garantit que toutes les features sont calculables et cohÃ©rentes. Pas d'imputation pour Ã©viter d'introduire des biais.

## ğŸ¤– ModÃ¨le SupervisÃ©

### Choix du ModÃ¨le : HistGradientBoostingClassifier

**Pourquoi ce modÃ¨le** :
- âœ… EfficacitÃ© : EntraÃ®nement rapide sur de grands datasets
- âœ… Performance : Excellent pour les problÃ¨mes de classification binaire
- âœ… Robustesse : GÃ¨re bien les features mixtes (numÃ©riques + catÃ©gorielles)
- âœ… InterprÃ©tabilitÃ© : Importance des features disponible

### Architecture du Pipeline

Le pipeline complet est composÃ© de deux Ã©tapes :

```python
pipeline = Pipeline([
    ("preprocessor", ColumnTransformer(...)),  # Preprocessing
    ("classifier", HistGradientBoostingClassifier(...)),  # ModÃ¨le
])
```

## ğŸ“ EntraÃ®nement et Optimisation

### 1. Division des DonnÃ©es

**MÃ©thode** : `GroupShuffleSplit` pour maintenir l'intÃ©gritÃ© des patients.

**RÃ©partition** :
- **Train** : 60% des patients
- **Validation** : 20% des patients
- **Test** : 20% des patients

**Pourquoi** : Ã‰vite le **data leakage** inter-patient (mÃªme patient dans train et test).

### 2. Recherche d'HyperparamÃ¨tres (Grid Search)

**HyperparamÃ¨tres optimisÃ©s** :

| HyperparamÃ¨tre | Valeurs testÃ©es |
|----------------|-----------------|
| `learning_rate` | 0.05, 0.1 |
| `max_depth` | None, 6, 10 |
| `max_iter` | 200, 400 |

**Total** : 2 Ã— 3 Ã— 2 = **12 combinaisons** testÃ©es

### 3. Optimisation du Seuil de Classification

Pour chaque combinaison d'hyperparamÃ¨tres :

1. **EntraÃ®nement** du modÃ¨le sur l'ensemble d'entraÃ®nement
2. **Calcul des scores** de probabilitÃ© sur l'ensemble de validation
3. **Balayage de 100 seuils** (quantiles de 50% Ã  99.5%)
4. **SÃ©lection du seuil** qui maximise l'accuracy
5. **Contrainte** : recall â‰¥ 25% (Ã©vite la solution triviale "tout prÃ©dire Normal")

**Formule de prÃ©diction** :
```
y_pred = 1 si score â‰¥ Ï„
y_pred = 0 sinon
```

### 4. SÃ©lection du Meilleur ModÃ¨le

**CritÃ¨res de sÃ©lection** (par ordre de prioritÃ©) :
1. **Accuracy sur validation** (critÃ¨re principal)
2. **Balanced Accuracy** (en cas d'Ã©galitÃ©)
3. **AUC-PR** (en cas d'Ã©galitÃ© supplÃ©mentaire)

### 5. EntraÃ®nement Final

Une fois le meilleur modÃ¨le sÃ©lectionnÃ© :

1. **RÃ©-entraÃ®nement** sur train + validation
2. **Re-calibration** du seuil sur train + validation
3. **Ã‰valuation finale** sur l'ensemble de test

## ğŸ“ˆ Ã‰valuation

### MÃ©triques UtilisÃ©es

| MÃ©trique | Formule | Description |
|----------|---------|-------------|
| **Accuracy** | (TP + TN) / (TP + TN + FP + FN) | Proportion de prÃ©dictions correctes |
| **Balanced Accuracy** | 0.5 Ã— (TP/(TP+FN) + TN/(TN+FP)) | Accuracy Ã©quilibrÃ©e pour les classes dÃ©sÃ©quilibrÃ©es |
| **Precision** | TP / (TP + FP) | Proportion de vrais positifs parmi les prÃ©dictions positives |
| **Recall** | TP / (TP + FN) | Proportion d'anomalies dÃ©tectÃ©es |
| **F1-Score** | 2 Ã— (Precision Ã— Recall) / (Precision + Recall) | Moyenne harmonique de prÃ©cision et recall |
| **AUC-ROC** | Aire sous la courbe ROC | CapacitÃ© Ã  distinguer les classes |
| **AUC-PR** | Aire sous la courbe Precision-Recall | Performance sur classe minoritaire |

### RÃ©sultats sur l'Ensemble de Test

| MÃ©trique | Valeur |
|----------|--------|
| **Accuracy** | **95.21%** |
| Balanced Accuracy | 90.34% |
| Precision | 86.53% |
| Recall | 83.17% |
| F1-Score | 84.82% |
| AUC-ROC | 98.85% |
| AUC-PR | 94.71% |

### Matrice de Confusion

| | PrÃ©dit Normal | PrÃ©dit Anomalie |
|---|---|---|
| **RÃ©el Normal** | 1571 | 40 |
| **RÃ©el Anomalie** | 52 | 257 |

**Seuil utilisÃ©** : 0.5078

### Analyse des RÃ©sultats

âœ… **PrÃ©cision Ã©levÃ©e** : 95.21% d'accuracy, excellent pour un problÃ¨me de dÃ©tection d'anomalies

âœ… **Bon Ã©quilibre** : Balanced Accuracy de 90.34% indique que le modÃ¨le performe bien sur les deux classes malgrÃ© le dÃ©sÃ©quilibre (prÃ©valence = 16.09%)

âœ… **Recall acceptable** : 83.17% de recall signifie que le modÃ¨le dÃ©tecte 83% des anomalies rÃ©elles

âœ… **Peu de faux positifs** : Seulement 40 faux positifs sur 1611 cas normaux (2.48%)

âœ… **Peu de faux nÃ©gatifs** : 52 faux nÃ©gatifs sur 309 anomalies rÃ©elles (16.83%)

## ğŸš€ Utilisation

### 1. EntraÃ®nement du ModÃ¨le

```bash
python -m src.train_supervised
```

> Besoin de limiter l'accuracy (ex: viser ~95%) ? Utilisez l'argument optionnel :

```bash
python -m src.train_supervised --target-accuracy 0.95 --target-accuracy-tolerance 0.01
```

`--target-accuracy` accepte une valeur entre 0 et 1 (ou 0-100) et ajuste automatiquement le seuil de dÃ©cision pour se rapprocher de cette accuracy tout en respectant la contrainte de recall minimale.

> Besoin d'augmenter la sensibilitÃ© aux anomalies ? Ajustez le poids de la classe positive :

```bash
python -m src.train_supervised --positive-class-weight 2.0
```

Par dÃ©faut le modÃ¨le utilise `class_weight="balanced"` pour compenser l'imbalance. Avec `--positive-class-weight`, vous imposez manuellement un ratio (classe 0 â†’ 1.0, classe 1 â†’ valeur fournie) tout en conservant les donnÃ©es originales.

**Sorties** :
- `artifacts/supervised_pipeline.joblib` : Pipeline complet
- `artifacts/supervised_threshold.json` : Seuil optimal
- `artifacts/supervised_test_metrics.json` : MÃ©triques sur test
- `artifacts/supervised_test_roc.png` : Courbe ROC
- `artifacts/supervised_test_pr.png` : Courbe Precision-Recall

### ğŸ““ Processus complet (Notebook)

Besoin d'un fil conducteur unique qui regroupe toutes les Ã©tapes (prÃ©paration des donnÃ©es, feature engineering centrÃ© patient, entraÃ®nement, optimisation du seuil, Ã©valuation et infÃ©rence) ?  
Consultez le notebook `notebooks/complete_preprocessing_and_model.ipynb`. Il documente pas Ã  pas le pipeline complet, avec du code exÃ©cutable et des commentaires pour reproduire exactement les rÃ©sultats prÃ©sentÃ©s dans ce dÃ©pÃ´t.

### 2. Preprocessing des DonnÃ©es

```python
from src.preprocessing_supervised import build_features_patient_centric

# Charger les donnÃ©es
df = pd.read_csv("data/clinical_alerts.csv")

# Feature engineering
df_feat, num_cols, cat_cols = build_features_patient_centric(df, window=7)
```

### 3. Chargement du ModÃ¨le

```python
from src.preprocessing_supervised import load_supervised_model

# Charger le pipeline
pipeline = load_supervised_model("artifacts/supervised_pipeline.joblib")
```

### 4. PrÃ©diction

```python
from src.preprocessing_supervised import predict_with_supervised_model

# PrÃ©parer les features
X = df_feat[num_cols + cat_cols]

# PrÃ©dire
results = predict_with_supervised_model(pipeline, X)

# RÃ©sultats
scores = results['scores']  # ProbabilitÃ©s
predictions = results['predictions']  # PrÃ©dictions binaires (0/1)
threshold = results['threshold_used']  # Seuil utilisÃ©
```

### 5. PrÃ©diction sur un Nouvel Ã‰chantillon

```python
from src.preprocessing_supervised import build_features_patient_centric, load_supervised_model, predict_with_supervised_model

# Charger le modÃ¨le
pipeline = load_supervised_model()

# Nouvel Ã©chantillon (doit contenir l'historique du patient pour les features delta/z-score)
sample_df = pd.DataFrame([{
    'patient_id': 1,
    'timestamp': '2024-01-15',
    'heart_rate': 85,
    'hr_variability': 45,
    # ... autres colonnes
}])

# Feature engineering
df_feat, num_cols, cat_cols = build_features_patient_centric(sample_df, window=7)

# PrÃ©dire
X = df_feat[num_cols + cat_cols]
results = predict_with_supervised_model(pipeline, X)
```

## ğŸ“ Structure du Projet

```
P_AI/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ clinical_alerts.csv          # DonnÃ©es d'entraÃ®nement
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing_supervised.py  # Feature engineering et preprocessing
â”‚   â”œâ”€â”€ train_supervised.py          # Script d'entraÃ®nement
â”‚   â””â”€â”€ inference_utils.py           # Utilitaires d'infÃ©rence
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ supervised_pipeline.joblib   # ModÃ¨le entraÃ®nÃ©
â”‚   â”œâ”€â”€ supervised_threshold.json    # Seuil optimal
â”‚   â”œâ”€â”€ supervised_test_metrics.json # MÃ©triques de test
â”‚   â”œâ”€â”€ supervised_test_roc.png     # Courbe ROC
â”‚   â””â”€â”€ supervised_test_pr.png      # Courbe Precision-Recall
â””â”€â”€ notebooks/
    â””â”€â”€ complete_preprocessing_and_model.ipynb  # Notebook d'analyse complÃ¨te
```

## ğŸ“¦ DÃ©pendances

- `pandas` : Manipulation de donnÃ©es
- `numpy` : Calculs numÃ©riques
- `scikit-learn` : Machine learning
- `matplotlib` : Visualisation
- `joblib` : Sauvegarde/chargement de modÃ¨les

## ğŸ” Points ClÃ©s du Preprocessing

### Pourquoi CentrÃ© Patient ?

Les valeurs absolues (ex: frÃ©quence cardiaque = 85 bpm) ne sont pas significatives sans contexte. Un patient avec une frÃ©quence cardiaque normale de 60 bpm et un autre avec une normale de 90 bpm ont des profils diffÃ©rents.

**Solution** : Utiliser des features relatives au profil du patient (delta, z-score) plutÃ´t que des valeurs absolues.

### Pourquoi Rolling Windows ?

Les statistiques sur une fenÃªtre glissante de 7 jours capturent :
- La tendance rÃ©cente du patient
- La variabilitÃ© normale du patient
- Les changements progressifs ou soudains

### Pourquoi Pas d'Imputation ?

Les valeurs manquantes dans les features delta/z-score indiquent souvent :
- DonnÃ©es insuffisantes pour calculer les statistiques glissantes
- Nouveaux patients sans historique

L'imputation pourrait introduire des biais, donc on prÃ©fÃ¨re supprimer ces cas.

## ğŸ“ Notes Importantes

1. **Historique Patient Requis** : Les features delta/z-score nÃ©cessitent un historique de 7 jours minimum pour chaque patient. Pour les nouveaux patients, ces features seront NaN et seront supprimÃ©es.

2. **Ordre Temporel** : Les donnÃ©es doivent Ãªtre triÃ©es par `patient_id` et `timestamp` avant le feature engineering.

3. **Seuil Optimal** : Le seuil de classification (0.5078) a Ã©tÃ© optimisÃ© sur l'ensemble de validation. Il peut Ãªtre ajustÃ© selon les besoins cliniques (prioritÃ© recall vs precision).

4. **ReproductibilitÃ©** : Le modÃ¨le utilise `random_state=42` pour garantir la reproductibilitÃ©.

## ğŸ¯ Conclusion

Le systÃ¨me de dÃ©tection d'alertes cliniques utilise un preprocessing sophistiquÃ© centrÃ© patient et un modÃ¨le supervisÃ© performant (HistGradientBoostingClassifier). Les rÃ©sultats montrent :

- âœ… **Performance Ã©levÃ©e** : 95.21% d'accuracy avec un bon Ã©quilibre entre prÃ©cision et recall
- âœ… **Robustesse** : Le feature engineering centrÃ© patient capture efficacement les dÃ©viations intra-patient
- âœ… **ReproductibilitÃ©** : Pipeline complet sauvegardÃ© pour l'infÃ©rence
- âœ… **FlexibilitÃ©** : Support de diffÃ©rentes stratÃ©gies de seuil selon les besoins cliniques

Le modÃ¨le est prÃªt pour l'intÃ©gration dans un systÃ¨me de production pour la dÃ©tection d'alertes cliniques en temps rÃ©el.

